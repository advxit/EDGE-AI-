{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/advxit/EDGE-AI-/blob/main/Untitled6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "6pE5Q3JhtC6k",
        "outputId": "7c29d01c-d81f-425b-b023-27ecb12cb59a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: snntorch==0.5.0 in /usr/local/lib/python3.12/dist-packages (0.5.0)\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from snntorch==0.5.0) (2.9.0+cu126)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from snntorch==0.5.0) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from snntorch==0.5.0) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from snntorch==0.5.0) (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.1.0->snntorch==0.5.0) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.1.0->snntorch==0.5.0) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.1.0->snntorch==0.5.0) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.1.0->snntorch==0.5.0) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.1.0->snntorch==0.5.0) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.1.0->snntorch==0.5.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.1.0->snntorch==0.5.0) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.1.0->snntorch==0.5.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.1.0->snntorch==0.5.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.1.0->snntorch==0.5.0) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.1.0->snntorch==0.5.0) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.1.0->snntorch==0.5.0) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.1.0->snntorch==0.5.0) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.1.0->snntorch==0.5.0) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.1.0->snntorch==0.5.0) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.1.0->snntorch==0.5.0) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.1.0->snntorch==0.5.0) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.1.0->snntorch==0.5.0) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.1.0->snntorch==0.5.0) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.1.0->snntorch==0.5.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.1.0->snntorch==0.5.0) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.1.0->snntorch==0.5.0) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.1.0->snntorch==0.5.0) (3.5.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->snntorch==0.5.0) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->snntorch==0.5.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->snntorch==0.5.0) (4.61.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->snntorch==0.5.0) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->snntorch==0.5.0) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->snntorch==0.5.0) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->snntorch==0.5.0) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->snntorch==0.5.0) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->snntorch==0.5.0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->snntorch==0.5.0) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->snntorch==0.5.0) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.1.0->snntorch==0.5.0) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.1.0->snntorch==0.5.0) (3.0.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.61.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install snntorch==0.5.0\n",
        "!pip install torch\n",
        "!pip install numpy\n",
        "\n",
        "!pip install matplotlib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fe5a6b0"
      },
      "source": [
        "### Cell 1: Installation of Libraries\n",
        "\n",
        "This cell is responsible for installing the necessary Python libraries required for the project. Each `!pip install` command executes a shell command to install a specific package:\n",
        "\n",
        "*   `!pip install snntorch==0.5.0`: Installs `snntorch`, a Python library for building and simulating spiking neural networks (SNNs) with PyTorch. The `==0.5.0` specifies a particular version to ensure compatibility.\n",
        "*   `!pip install torch`: Installs PyTorch, an open-source machine learning framework used for deep learning applications, including building and training neural networks.\n",
        "*   `!pip install numpy`: Installs NumPy, the fundamental package for numerical computing in Python, providing support for large, multi-dimensional arrays and matrices, along with a collection of high-level mathematical functions to operate on these arrays.\n",
        "*   `!pip install matplotlib`: Installs Matplotlib, a comprehensive library for creating static, animated, and interactive visualizations in Python."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "027b9633"
      },
      "source": [
        "### Cell 2: Importing Essential Modules\n",
        "\n",
        "This cell imports various modules and functions from the previously installed libraries. These imports make specific functionalities available for use in the subsequent code:\n",
        "\n",
        "*   `import torch.nn as nn`: Imports the `nn` module from PyTorch, which contains classes for building neural network layers (like `Linear`, `Conv2d`, etc.), activation functions, and loss functions.\n",
        "*   `import torch`: Imports the core PyTorch library, providing fundamental tensor operations and utilities.\n",
        "*   `from torch.utils.data import DataLoader`: Imports `DataLoader` from PyTorch's `utils.data` module. `DataLoader` is used for iterating over datasets in batches, shuffling data, and parallelizing data loading.\n",
        "*   `from torchvision import datasets, transforms`: Imports `datasets` and `transforms` from `torchvision`. `datasets` provides access to common datasets (like MNIST), and `transforms` offers common image transformations (like converting to tensor, normalization).\n",
        "*   `import numpy as np`: Imports NumPy and aliases it as `np`, a common convention.\n",
        "*   `import matplotlib.pyplot as plt`: Imports the `pyplot` module from Matplotlib and aliases it as `plt`, used for plotting and visualization.\n",
        "*   `import snntorch as snn`: Imports the `snntorch` library and aliases it as `snn`, making its spiking neural network components easily accessible."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b91e528f"
      },
      "source": [
        "### Cell 3: Leaky Integrate-and-Fire (LIF) Neuron Initialization and Input Signal\n",
        "\n",
        "This cell sets up a single Leaky Integrate-and-Fire (LIF) neuron model and defines an input signal for it:\n",
        "\n",
        "*   `lif = snn.Leaky(beta=0.95)`: Initializes a `Leaky` neuron from the `snntorch` library. The `beta` parameter (0.95) represents the decay rate of the membrane potential. A `beta` of 0.95 means that the membrane potential will decay by 5% at each time step if there's no input.\n",
        "*   `num_steps = 200`: Defines the number of simulation steps for which the LIF neuron will be observed. This means the neuron will be simulated for 200 discrete time steps.\n",
        "*   `x = torch.cat((torch.zeros(30), torch.ones(40)*0.1, torch.zeros(130)))`: Creates a 1D PyTorch tensor `x` which will serve as the input current to the LIF neuron over time. It's composed of:\n",
        "    *   `torch.zeros(30)`: 30 time steps of zero input.\n",
        "    *   `torch.ones(40)*0.1`: 40 time steps of a constant input current of 0.1.\n",
        "    *   `torch.zeros(130)`: 130 time steps of zero input again.\n",
        "    This creates a pulsed input signal: no input for 30 steps, a small positive current for 40 steps, and then no input for the remaining 130 steps."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8a93f46d"
      },
      "source": [
        "### Cell 4: Initializing Membrane Potential and Spike Output\n",
        "\n",
        "This cell initializes the internal state variables of the LIF neuron:\n",
        "\n",
        "*   `mem = torch.zeros(1)`: Initializes the membrane potential (`mem`) of the neuron to zero. The `torch.zeros(1)` creates a tensor of size 1 containing a single zero. This represents the initial voltage across the neuron's membrane.\n",
        "*   `spk = torch.zeros(1)`: Initializes the spike output (`spk`) of the neuron to zero. This tensor will hold whether the neuron spiked (typically 1) or not (0) at a given time step."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "db792010"
      },
      "source": [
        "### Cell 5: Simulating the Leaky Integrate-and-Fire (LIF) Neuron\n",
        "\n",
        "This cell contains a loop that simulates the behavior of the LIF neuron over the `num_steps` defined earlier:\n",
        "\n",
        "*   `mem_rec = []`: Initializes an empty list to store the membrane potential at each time step.\n",
        "*   `spk_rec = []`: Initializes an empty list to store the spike output at each time step.\n",
        "*   `for step in range(num_steps):`: This loop iterates `num_steps` (200 times in this case), simulating each discrete time step.\n",
        "    *   `spk, mem = lif(x[step], mem)`: This is the core line. It calls the `lif` neuron object with the current input `x[step]` and the previous membrane potential `mem`. The `lif` neuron's `forward` method (implicitly called here) calculates the new spike output (`spk`) and the updated membrane potential (`mem`) based on the input current, the previous membrane potential, and its internal parameters (like `beta`).\n",
        "    *   `mem_rec.append(mem.item())`: The updated membrane potential `mem` (which is a tensor) is extracted as a Python number (`.item()`) and appended to the `mem_rec` list.\n",
        "    *   `spk_rec.append(spk.item())`: Similarly, the spike output `spk` is extracted as a Python number and appended to the `spk_rec` list.\n",
        "\n",
        "After this loop, `mem_rec` will contain the membrane potential trajectory, and `spk_rec` will contain the spike train (sequence of 0s and 1s indicating firing) of the LIF neuron in response to the input `x`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "004248df"
      },
      "source": [
        "### Cell 6: Converting Recorded Data to PyTorch Tensors\n",
        "\n",
        "This cell converts the lists of recorded membrane potentials and spikes into PyTorch tensors:\n",
        "\n",
        "*   `mem_rec = torch.tensor(mem_rec)`: Converts the `mem_rec` list (which holds Python floats) into a PyTorch tensor. This is done to enable further tensor operations and compatibility with PyTorch's computational graph.\n",
        "*   `spk_rec = torch.tensor(spk_rec)`: Similarly, converts the `spk_rec` list into a PyTorch tensor. Using tensors is crucial for leveraging PyTorch's optimized operations, especially on GPUs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73a7b85d"
      },
      "source": [
        "### Cell 7: Data Loading and Device Configuration\n",
        "\n",
        "This cell sets up crucial parameters for data loading and specifies the computational device:\n",
        "\n",
        "*   `batch_size = 128`: Defines the number of samples that will be processed in one batch during training. Using batches helps in efficient training and memory management.\n",
        "*   `data_path ='/data/mnist'`: Specifies the directory where the MNIST dataset will be downloaded and stored. It's a common practice to use a dedicated directory for datasets.\n",
        "*   `dtype =torch.float`: Sets the default data type for tensors to `torch.float` (32-bit floating-point numbers). This is a standard precision for many deep learning tasks.\n",
        "*   `device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")`: This line dynamically selects the computing device. If a CUDA-enabled GPU is available, it will use `'cuda'` for faster computations; otherwise, it defaults to `'cpu'`. This ensures that the code can run on systems with or without a GPU."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ec51ab89"
      },
      "source": [
        "### Cell 8: Data Transformation and MNIST Dataset Loading\n",
        "\n",
        "This cell prepares the MNIST dataset by defining transformations and loading the training and testing splits:\n",
        "\n",
        "*   `transform = transforms.Compose([...])`: Creates a sequence of transformations to be applied to the MNIST images. `transforms.Compose` chains multiple transformations together:\n",
        "    *   `transforms.ToTensor()`: Converts a PIL Image or NumPy array to a PyTorch `FloatTensor` and scales the pixel values from the range \\[0, 255\\] to \\[0.0, 1.0\\].\n",
        "    *   `transforms.Normalize((0.1307,), (0.3081,))`: Normalizes the tensor image with a mean of 0.1307 and a standard deviation of 0.3081. These values are common for the MNIST dataset and help in stabilizing training.\n",
        "    *   `transforms.Grayscale()`: Converts the image to grayscale. MNIST images are already grayscale, but this ensures consistency in case of any variations.\n",
        "    *   `transforms.Normalize((0,), (1,))`: This normalization step with mean 0 and std dev 1 essentially scales the data to have a unit variance and zero mean *after* the previous normalization. For grayscale images that are already 0-1, this might be redundant or could be intended to ensure pixel values are correctly distributed for a specific SNN input type.\n",
        "*   `mnist_train = datasets.MNIST(data_path, train=True, download=True, transform=transform)`: Loads the MNIST training dataset. It specifies the `data_path`, `train=True` for the training split, `download=True` to download if not already present, and applies the defined `transform`.\n",
        "*   `mnist_test = datasets.MNIST(data_path, train=False, download=True, transform=transform)`: Loads the MNIST test dataset, similar to the training set but with `train=False`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f51d8812"
      },
      "source": [
        "### Cell 9: Creating DataLoaders for Training and Testing\n",
        "\n",
        "This cell creates `DataLoader` objects, which are essential for iterating through the datasets in mini-batches during training and evaluation:\n",
        "\n",
        "*   `train_loader = DataLoader(mnist_train, batch_size=batch_size, shuffle=True, drop_last=True)`:\n",
        "    *   `mnist_train`: The dataset to load data from.\n",
        "    *   `batch_size=batch_size`: Specifies the number of samples per batch (128, as defined in Cell 7).\n",
        "    *   `shuffle=True`: The data will be shuffled at the beginning of each epoch. This is crucial for training to prevent the model from learning the order of samples.\n",
        "    *   `drop_last=True`: If the dataset size is not perfectly divisible by the batch size, the last incomplete batch will be dropped. This ensures all batches have the same size, which can simplify model architecture and training logic.\n",
        "*   `test_loader = DataLoader(mnist_test, batch_size=batch_size, shuffle=True, drop_last = True)`:\n",
        "    *   Similar to `train_loader`, but uses the `mnist_test` dataset. Shuffling and dropping the last batch are also applied here, which is common for consistent evaluation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fb760632"
      },
      "source": [
        "### Cell 10: Defining Spiking Neural Network (SNN) Parameters\n",
        "\n",
        "This cell defines various hyper-parameters and network architecture parameters that will be used for building the Spiking Neural Network:\n",
        "\n",
        "*   `num_inputs = 784`: This represents the number of input features. For MNIST images (28x28 pixels), 28 * 28 = 784. Each pixel will be an input to the first layer of the network.\n",
        "*   `num_hidden = 1000`: Defines the number of neurons in the hidden layer of the network. This is a common practice to have a larger hidden layer for feature extraction.\n",
        "*   `num_outputs = 10`: Represents the number of output classes. For MNIST, there are 10 digits (0-9), so there are 10 output neurons, each corresponding to a digit.\n",
        "*   `num_steps = 25`: This parameter specifies the number of simulation steps (time steps) over which the SNN will process each input sample. In SNNs, computation unfolds over time.\n",
        "*   `beta = 0.95`: This is the decay rate for the membrane potential of the LIF neurons used in the network layers, as seen in Cell 3. A higher `beta` means slower decay."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fa3bed0"
      },
      "source": [
        "### Cell 11: Spiking Neural Network (SNN) Model Definition\n",
        "\n",
        "This cell defines the `Net` class, which is a PyTorch `nn.Module` representing the spiking neural network architecture:\n",
        "\n",
        "*   `class Net(nn.Module):` Defines a neural network class inheriting from `nn.Module`.\n",
        "*   `def __init__(self):`: The constructor method where network layers and SNN specific components are initialized.\n",
        "    *   `super().__init__()`: Calls the constructor of the parent `nn.Module` class.\n",
        "    *   `self.fc1 = nn.Linear(num_inputs, num_hidden)`: Defines the first fully connected (linear) layer. It takes `num_inputs` (784) and outputs `num_hidden` (1000) features.\n",
        "    *   `self.lif1 = snn.Leaky(beta=beta)`: Instantiates a Leaky Integrate-and-Fire neuron layer from `snntorch` for the first layer, using the global `beta`.\n",
        "    *   `self.fc2 = nn.Linear(num_hidden, num_outputs)`: Defines the second fully connected layer, taking `num_hidden` features and outputting `num_outputs` (10) features.\n",
        "    *   `self.lif2 = snn.Leaky(beta=beta)`: Instantiates another Leaky Integrate-and-Fire neuron layer for the second layer.\n",
        "    *   `self.numsteps = num_steps`: Stores the `num_steps` parameter as an attribute of the network.\n",
        "*   `def forward(self, x):`: The `forward` method defines how data flows through the network.\n",
        "    *   `mem1 = self.lif1.init_leaky()`: Initializes the membrane potential for the first LIF layer. `init_leaky()` is a `snntorch` method to get a zero-initialized membrane potential.\n",
        "    *   `mem2 = self.lif2.init_leaky()`: Initializes the membrane potential for the second LIF layer.\n",
        "    *   `spk2_rec = []` and `mem2_rec = []`: Lists to record the spike outputs and membrane potentials of the second (output) LIF layer over time.\n",
        "    *   `for step in range(num_steps):`: This loop simulates the SNN's behavior over `num_steps` for each input. This is where the temporal dynamics of SNNs are handled.\n",
        "        *   `cur11 = self.fc1(x.flatten(1))`: The input `x` (likely a batch of images) is first flattened from its spatial dimensions (e.g., `batch_size, 1, 28, 28` to `batch_size, 784`) and then passed through the first linear layer (`self.fc1`) to produce input current `cur11` for the first LIF layer.\n",
        "        *   `spk1, mem1 = self.lif1(cur1, mem1)`: **Correction needed**: There is a typo here. It should be `cur11` instead of `cur1`. This line passes the current from `fc1` (`cur11`) and the previous membrane potential `mem1` through the first LIF neuron layer. It returns the new spikes `spk1` and updated membrane potential `mem1`.\n",
        "        *   `cur2 = self.fc2(spk1)`: The spikes (`spk1`) from the first LIF layer act as input current for the second linear layer (`self.fc2`).\n",
        "        *   `spk2, mem2 = self.lif2(cur2, mem2)`: The current from `fc2` (`cur2`) and the previous membrane potential `mem2` are passed through the second LIF neuron layer, producing output spikes `spk2` and updated `mem2`.\n",
        "        *   `spk2_rec.append(spk2)` and `mem2_rec.append(mem2)`: The output spikes and membrane potentials from the second layer are recorded at each time step.\n",
        "    *   `return torch.stack(spk2_rec, dim=0), torch.stack(mem2_rec, dim=0)`: After the simulation loop, the recorded lists of spikes and membrane potentials are stacked into single tensors along a new dimension (dimension 0), making them `(num_steps, batch_size, num_outputs)` shaped tensors. These represent the time-series output of the SNN.\n",
        "*   `net = Net().to(device)`: An instance of the `Net` class is created and then moved to the specified `device` (CPU or GPU) for computation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bd76daf"
      },
      "source": [
        "### Cell 12: Empty Cell\n",
        "\n",
        "This cell is currently empty. It might have been intended for future code or is a remnant from previous editing. It has no functional impact on the notebook's execution."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import snntorch as snn\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ywUGi_qhI19W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lif = snn.Leaky(beta=0.95)\n",
        "num_steps = 200\n",
        "x = torch.cat((torch.zeros(30), torch.ones(40)*0.1, torch.zeros(130)))\n"
      ],
      "metadata": {
        "id": "m2tGL1k1RlSn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mem = torch.zeros(1)\n",
        "spk = torch.zeros(1)\n",
        "\n"
      ],
      "metadata": {
        "id": "JE75UvZlR_YK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mem_rec = []\n",
        "spk_rec = []\n",
        "\n",
        "for step in range(num_steps):\n",
        "    spk, mem = lif(x[step], mem)\n",
        "    mem_rec.append(mem.item())\n",
        "    spk_rec.append(spk.item())\n"
      ],
      "metadata": {
        "id": "A8qv3SQHSSN_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mem_rec = torch.tensor(mem_rec)\n",
        "spk_rec = torch.tensor(spk_rec)\n"
      ],
      "metadata": {
        "id": "Nn_9MuYUSUN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import device\n",
        "batch_size = 128\n",
        "data_path ='/data/mnist'\n",
        "dtype =torch.float\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
      ],
      "metadata": {
        "id": "60EnrnCsGvOY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.1307,), (0.3081,)),\n",
        "            transforms.Grayscale(),\n",
        "            transforms.Normalize((0,), (1,))])\n",
        "\n",
        "mnist_train = datasets.MNIST(data_path, train=True, download=True, transform=transform)\n",
        "mnist_test = datasets.MNIST(data_path, train=False, download=True, transform=transform)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6EOl1O4uLWEm",
        "outputId": "3c81484c-660a-4b53-bf60-6ec59dacc7b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:02<00:00, 4.46MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 131kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:01<00:00, 1.23MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 8.08MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(mnist_train, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "test_loader = DataLoader(mnist_test, batch_size=batch_size, shuffle=True, drop_last = True)"
      ],
      "metadata": {
        "id": "z_jJ35lANEWq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_inputs = 784\n",
        "num_hidden = 1000\n",
        "num_outputs = 10\n",
        "\n",
        "num_steps = 25\n",
        "beta = 0.95 #membrane potential decreases by 5%"
      ],
      "metadata": {
        "id": "K3ZSREYONgyl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(num_inputs, num_hidden)\n",
        "        self.lif1 = snn.Leaky(beta=beta)\n",
        "        self.fc2 = nn.Linear(num_hidden, num_outputs)\n",
        "        self.lif2 = snn.Leaky(beta=beta)\n",
        "        self.numsteps = num_steps\n",
        "\n",
        "    def forward(self, x):\n",
        "        mem1 = self.lif1.init_leaky()\n",
        "        mem2 = self.lif2.init_leaky()\n",
        "        spk2_rec = []\n",
        "        mem2_rec = []\n",
        "\n",
        "        for step in range(num_steps):\n",
        "          cur11 = self.fc1(x.flatten(1))\n",
        "          spk1, mem1 = self.lif1(cur1, mem1)\n",
        "          cur2 = self.fc2(spk1)\n",
        "          spk2, mem2 = self.lif2(cur2, mem2)\n",
        "          spk2_rec.append(spk2)\n",
        "          mem2_rec.append(mem2)\n",
        "\n",
        "        return torch.stack(spk2_rec, dim=0), torch.stack(mem2_rec, dim=0)\n",
        "net = Net().to(device)"
      ],
      "metadata": {
        "id": "aLW7U-S0Nz14"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NwtokyFgJtGh"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyMGKTM/7jp1KeH1AOcXzIq6",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
